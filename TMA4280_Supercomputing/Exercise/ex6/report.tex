\documentclass{article}
\usepackage{a4wide}
\usepackage{german}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
%\usepackage[dvips]{epsfig}
%\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{nomencl}
\usepackage[pdftex]{graphicx}

\pagestyle{fancy}
\lhead{\footnotesize \parbox{11cm}{Andreas Johann H\"ormer (753179), Daniel Tormoen}}
\rhead{\footnotesize {Assignment 6}}
\chead{\footnotesize {TTT4170}}

\begin{document}
\section{Problem description}
The implementation shall solve the two-dimensional poisson problem 
\begin{equation}
-\bigtriangledown^2=f\;in\;\Omega = (0,1)x(0,1)
\end{equation}
\begin{equation}
u = 0\;on\;\delta\Omega
\end{equation}
The given poisson equation is an elliptic partial differential equation. The problem is solving this equation with given boundary conditions. 
The problem should be discretized with (n+1) points in each spatial direction. The standard 5-point-stencil to discretize the Laplace operator $\bigtriangledown$ has to be used. To obtain a solution in $O(n\cdot log(n))$ the DST should be applied.
\section{Solution strategies}
\subsection{LU factorization}
LU (lower upper) factorization decomposes a matrix in an upper and a lower triangular matrix. This can be done using Gaussian elimination. For symmetric matrizes this can also be done using the cholesky decomposition. The matrix decomposition follows following rule
\begin{equation}
A=LU
\end{equation}
where A is the original matrix, L the lower triangular matrix and U the upper triangular matrix.\\
This solution strategy is not very usable as solver in parallel contexts. The sequential nature (pivoting, substitution, ...) makes ithard for parralelization.

\subsection{diagonalization}
The diagonalization can be done in three steps:
\begin{enumerate}
\item $$\underline{\tilde{B}}=\underline{Q^T}\cdot\underline{B}\cdot\underline{Q}$$
\item $$\tilde{x_{ij}}=\frac{\tilde{b_{ij}}}{\lambda_i+\lambda_j}\;for\;1\leq i,j \leq N$$
\item $$\underline{X}=\underline{Q}\cdot\underline{\tilde{X}}\cdot\underline{Q^T}$$
\end{enumerate}
This algorithm scales very well with the number of unknowns and also scales very well in memory. It is better parallelizable than LU factorization. In an further step fourier transform (DST) can be applied.
\subsubsection{diagonalization using DST}
For this diagonalization technique a periodic function with period $2\pi$ is sampled at equidistant points. The function has to be odd and discretized on a equidistant mesh between 0 and $\pi$.The diagonalization can be done in the three following steps:
\begin{enumerate}
\item $$ \underline{\tilde{B}^T}=\underline{S^{-1}}\cdot\big((\underline{S}\cdot\underline{B})^T\big)$$
\item $$ \tilde{x_{ij}}=\frac{\tilde{b_{ij}}}{\lambda_i+\lambda_j}\;for\;1\leq i,j\leq N$$
\item $$ \underline{X}=\underline{S^{-1}}\cdot\big(\underline{S}\cdot(\underline{\tilde{X^T}})\big)^T$$
\end{enumerate}
\paragraph{row based matrix partitioning}
\paragraph{column based matrix partitioning}
\section{Implemented solution}
\subsection{matrix transpose}
\section{Environment}
\subsection{Supercomputer}
The used Kongull cluster is a CentOS 5.3 Linux cluster. The cluster has 1 login, 4 I/O and 93 compute nodes. Each node is equipped with 2x 6-core processors, with 6x 512KiB L1 cache and a common 6 MiB L3-cache. Kongull has 96 compute nodes and 1152 cores in total. All of the compute nodes are HP DL165 G6 servers, with
\begin{itemize}
\item 2 AMD Opteron model 2431 6-core (Istanbul) processors
\item 2.4 GHz core speed
\item 667 MHz (48 GiB nodes) or 800 MHz (24 GiB nodes) bus frequency
\item 149GiB 15000 RPM SAS system disc
\end{itemize}
This and further information about the used supercomputer can be found at the NTNU HPC homepage\footnote{https://www.hpc.ntnu.no/display/hpc/Kongull+Hardware, accessed: 18.03.2014}.
\subsection{Compiler}

For our solution we used following packages on kongull:
\begin{itemize}
\item intelcomp13.0.1
\item openmpi1.4.3-intel
\end{itemize}
\section{Results}
\subsection{Proof of Correctness}
	To verify the correctness of our method we used a series of tests to ensure each part of the algorithm is producing the results we expect. When we completed the transpose function we tested the transpose function for a variety of sizes and number of MPI processes to ensure that the function was producing the correct matrix. 

	Before we started work on the OpenMP parallelization we tried the complete algorithm with our own function that we knew the exact solution to. We then compared the numeric estimate our program produces to the exact solution to see if they converge. The initial values in each grid location are given by equation \ref{eqn:gridInitial}.

	\begin{equation}
		\label{eqn:gridInitial}
		f(x,y) = 5\pi^2 \sin(\pi x)* \sin(2\pi y)
	\end{equation}

	Equation \ref{eqn:gridExact} shows the exact solution for a grid point. We can find the maximum error at each grid point by taking the absolute value of the difference between the estimate for the grid point and the exact solution. We keep track of the maximum error for any grid point as a measurement of the error.

	\begin{equation}
		\label{eqn:gridExact}
		u(x,y) = \sin(\pi x) * \sin(2 \pi y)
	\end{equation}

	Using this method the maximum error should decrease by a factor of 4 every time we increase the number of grid points in a row by a factor of 2. Assume $e$ is the maximum error for a poisson numerical estimation of size $n \times n$. The error $e$ is given by \ref{eqn:error}.

	\begin{equation}
		\label{eqn:error}
		e = \Theta(\frac{1}{n^2})
	\end{equation}

	

\section{Analysis}

\section{Possible optimizations}

\section{Appendix}
\subsection{Code samples}
\end{document}
